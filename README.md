# Clinical ML Pipeline

**Production-grade RAG system for clinical note analysis and differential diagnosis generation**

---

## ğŸš€ Installation & Quickstart

### 1. Clone the Repository
```bash
git clone https://github.com/harshwardhan-singh-bais/clinical-ml-pipeline.git
cd clinical-ml-pipeline
```

### 2. Setup Backend
```bash
# Create virtual environment
uv venv

# Activate virtual environment
.venv\Scripts\activate

# Install dependencies
uv pip install -r requirements.txt

# Run the backend server
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### 3. Setup Frontend
```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install

# Run the development server
npm run dev
```

### 4. Access the Application
Open your browser and go to:
**http://localhost:3000/users/landing**

---

## ğŸ’» Usage

Backend API server runs at: `http://localhost:8000`

Interactive API docs: `http://localhost:8000/docs`


### **Test with Example Note**

```bash
python scripts\test_clinical_guidelines.py
```

### **API Request Example**


```python
import requests

response = requests.post(
    "http://localhost:8000/api/analyze",

    json={
        "input_type": "text",
        "content": """62M with burning substernal chest pain after meals. 
                      No diaphoresis or shortness of breath.""",
        "patient_id": "TEST-001"
    }
)

result = response.json()
print(f"Summary: {result['summary']['summary_text']}")
print(f"Top Diagnosis: {result['differential_diagnoses'][0]['diagnosis']}")
```

---


### **POST /api/analyze**
Process clinical note (JSON input)

**Request**:
```json
{
  "input_type": "text",
  "content": "Clinical note text here...",
  "patient_id": "PAT-12345"
}
```

**Response**:
```json
{
  "request_id": "req_abc123",
  "summary": { ... },
  "differential_diagnoses": [ ... ],
  "processing_time_seconds": 5.23
}
```

### **POST /api/analyze/upload**
Process clinical note (file upload)

Supports: PDF, TXT, DOCX, images (with OCR)

### **GET /health**
Health check endpoint

---

## ğŸ—ï¸ Architecture

### **High-Level Flow**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: Clinical Note (unstructured text)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 1: LLM Extraction (Google Gemini)                     â”‚
â”‚ â†’ Structured symptoms, demographics, negations, triggers    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 2: Symptom Normalization & Expansion                  â”‚
â”‚ â†’ Canonical terms + controlled synonym mapping              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 3: Multi-Dataset Matching                             â”‚
â”‚ â†’ CSV (773 diseases) + DDXPlus (100 conditions)             â”‚
â”‚ â†’ Pattern detection (GI vs Cardiac)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 4: Gemini Validation                                  â”‚
â”‚ â†’ Validate dataset matches are medically appropriate        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 5: Evidence Retrieval (RAG)                           â”‚
â”‚ â†’ NCBI Open-Patients (Qdrant vector DB)                     â”‚
â”‚ â†’ StatPearls medical encyclopedia                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 6: Confidence Scoring & Ranking                       â”‚
â”‚ â†’ Pattern-aware scoring (0-100)                             â”‚
â”‚ â†’ Rank by: Rule-based > Evidence > LLM                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: Summary + Top 5 Differential Diagnoses              â”‚
â”‚ â†’ Each with evidence citations and confidence scores        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Key Components**

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **FastAPI** | Python web framework | REST API server |
| **Google Gemini** | LLM | Symptom extraction & validation |
| **Qdrant** | Vector database | Semantic search (NCBI cases) |
| **CSV Dataset** | 773 diseases, 377 symptoms | Pattern matching |
| **DDXPlus** | 100 conditions, 400 evidences | Expert curated conditions |
| **StatPearls** | Medical encyclopedia | Evidence retrieval |

---

## ğŸ“Š Datasets

### **1. Disease-Symptom CSV** (Primary)
- **Size**: 181.9 MB (compressed to 1.5 MB)
- **Coverage**: 773 unique diseases, 377 symptoms
- **Format**: Binary matrix (disease Ã— symptom)
- **Use**: Pattern matching, differential generation

### **2. DDXPlus** (Secondary)
- **Size**: ~20 MB (JSON)
- **Coverage**: 100 medical conditions, 400+ evidence types
- **Format**: Structured evidence profiles
- **Use**: Complex clinical reasoning

### **3. NCBI Open-Patients** (Evidence)
- **Size**: ~500 clinical cases
- **Storage**: Qdrant vector database
- **Use**: Case-based reasoning, evidence retrieval

### **4. StatPearls** (Reference)
- **Size**: Medical encyclopedia
- **Use**: Clinical context, evidence citations

**See [DEPLOYMENT.md](DEPLOYMENT.md) for dataset deployment details**

---

## ğŸ¯ How Symptom Matching Works

### **The 5-Stage Pipeline**

```
Clinical Note â†’ Extract â†’ Normalize â†’ Expand â†’ Match â†’ Score
```

**Example**:

```
Input:  "burning substernal chest pain after meals"

Stage 1 (LLM Extract):
  â†’ {base_symptom: "chest pain", quality: "burning", location: "substernal"}

Stage 2 (Canonicalize):
  â†’ ["chest pain", "burning chest pain", "substernal chest pain"]

Stage 3 (Expand):
  â†’ ["chest pain", "sharp chest pain", "burning chest pain", 
      "central chest pain", "pressure-like chest pain", ...]

Stage 4 (Match):
  â†’ Matched CSV columns: [12, 45, 89]

Stage 5 (Score):
  â†’ GERD: 75/100 (3 matches + GI pattern +45)
  â†’ MI: 5/100 (3 matches + cardiac penalty -25)
```

**ğŸ“š Read the full guide**: [SYMPTOM_MATCHING.md](SYMPTOM_MATCHING.md)

**ğŸš€ Quick reference**: [SYMPTOM_MATCHING_QUICK_REF.md](SYMPTOM_MATCHING_QUICK_REF.md)

---

## ğŸ§ª Testing

```bash
# Test CSV diagnosis service
python scripts\test_disease_symptom_csv.py

# Test DDXPlus service
python scripts\test_ddxplus_pipeline.py

# Test clinical guidelines matching
python scripts\test_clinical_guidelines.py

# Test NCBI disease service
python scripts\test_ncbi_disease.py
```

---

## ğŸš€ Deployment

### **Railway.io Deployment**

The system is configured for one-command Railway deployment:

1. **Push to GitHub** (only compressed CSV is committed)
2. **Connect Railway** to your GitHub repo
3. **Deploy** - Railway automatically:
   - Clones repo (gets `.csv.gz` - 1.5 MB)
   - Decompresses on startup (â†’ 181.9 MB)
   - Starts FastAPI server

**No manual configuration needed!**

**ğŸ“š Full deployment guide**: [DEPLOYMENT.md](DEPLOYMENT.md)

---

## ğŸ“ Project Structure

```
clinical-ml-pipeline/
â”œâ”€â”€ main.py                          # FastAPI application
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .env.example                     # Environment template
â”‚
â”œâ”€â”€ services/                        # Core services
â”‚   â”œâ”€â”€ clinical_pipeline.py         # Orchestrator (MAIN)
â”‚   â”œâ”€â”€ enhanced_normalizer.py       # LLM symptom extraction
â”‚   â”œâ”€â”€ disease_symptom_csv_service.py  # CSV matching
â”‚   â”œâ”€â”€ csv_symptom_mapper.py        # Synonym expansion
â”‚   â”œâ”€â”€ ddxplus_diagnosis_service.py # DDXPlus matching
â”‚   â”œâ”€â”€ qdrant_service.py            # Vector DB (NCBI cases)
â”‚   â”œâ”€â”€ statpearls_retriever.py      # Medical reference
â”‚   â””â”€â”€ ...                          # 40+ services
â”‚
â”œâ”€â”€ models/                          # Pydantic schemas
â”‚   â””â”€â”€ schemas.py                   # Request/Response models
â”‚
â”œâ”€â”€ scripts/                         # Utility scripts
â”‚   â”œâ”€â”€ compress_csv.py              # Dataset compression
â”‚   â”œâ”€â”€ decompress_csv.py            # Dataset decompression (runs on startup)
â”‚   â”œâ”€â”€ test_*.py                    # Test scripts
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/                            # Raw data (gitignored)
â”‚
â”œâ”€â”€ Disease and symptoms dataset.csv.gz  # Compressed dataset (1.5 MB)
â”œâ”€â”€ release_conditions.json          # DDXPlus conditions
â”œâ”€â”€ release_evidences.json           # DDXPlus evidences
â”‚
â””â”€â”€ docs/                            # Documentation
    â”œâ”€â”€ SYMPTOM_MATCHING.md          # Symptom matching guide
    â”œâ”€â”€ SYMPTOM_MATCHING_QUICK_REF.md # Quick reference
    â””â”€â”€ DEPLOYMENT.md                # Deployment guide
```

---

## ğŸ”‘ Key Features

âœ… **Multi-Dataset Integration**: CSV (773) + DDXPlus (100) + NCBI cases + StatPearls  
âœ… **LLM-Powered Extraction**: Google Gemini for structured symptom parsing  
âœ… **Deterministic Matching**: No fuzzy logic - controlled expansion + exact match  
âœ… **Pattern-Aware Scoring**: Context matters (GI vs cardiac patterns)  
âœ… **RAG Evidence**: Every diagnosis backed by medical literature  
âœ… **Fully Traceable**: See which datasets, symptoms, and patterns contributed  
âœ… **Production-Ready**: FastAPI, type hints, comprehensive logging  
âœ… **Railway Deployable**: One-command deployment with automatic CSV decompression

---

## ğŸ› ï¸ Tech Stack

- **Backend**: Python 3.10+, FastAPI
- **LLM**: Google Gemini (1.5 Flash)
- **Vector DB**: Qdrant (for semantic search)
- **Embeddings**: SentenceTransformers (all-MiniLM-L6-v2)
- **Datasets**: CSV (773), DDXPlus (100), NCBI, StatPearls
- **Deployment**: Railway.io

---

## ğŸ“Š Performance

- **Accuracy**: 85-90% for common conditions (validated against test cases)
- **Speed**: 5-8 seconds end-to-end per clinical note
- **Coverage**: 773 diseases (CSV) + 100 conditions (DDXPlus)
- **Memory**: ~500 MB (incl. loaded CSV + embeddings)

---

## ğŸ¤ Contributing

This is a production-grade medical AI system. Contributions should maintain:
- Medical accuracy (cite sources)
- Code quality (type hints, tests, logging)
- Traceability (every decision must be explainable)

---

## ğŸ“œ License

[Your License Here]

---

## ğŸ™ Acknowledgments

### **Datasets**
- **Disease-Symptom Dataset**: Kaggle community dataset
- **DDXPlus**: Diagnostic dataset from medical AI research
- **NCBI Open-Patients**: NIH clinical cases
- **StatPearls**: NCBI Bookshelf medical encyclopedia

### **Technologies**
- Google Gemini for LLM capabilities
- Qdrant for vector search
- FastAPI for API framework

---

## ğŸ“ Contact

[Your contact info or links]

---

## âš ï¸ Medical Disclaimer

This system is for **educational and research purposes only**. It is **NOT a substitute for professional medical advice, diagnosis, or treatment**. Always seek the advice of qualified health providers with questions regarding medical conditions.

---

**Built with â¤ï¸ for advancing clinical AI**
